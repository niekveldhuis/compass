{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awvVOitQME-i"
   },
   "source": [
    "# Create Edge and Node List for Sargon Letters SNA\n",
    "This notebook creates an edge list and a node list for import into [Gephi](https://gephi.org/). The data are taken from the Sargon letters published online in [SAAo](http://oracc.org/saao), but the code can be used for other data sets as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ObSOWOqNME-k"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import json\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nmr-yBDrME-s"
   },
   "source": [
    "The `JSON` of saao/sargonletters has been parsed and transformed into a `csv` file called `sargonletters.csv`. This file has been moved to the directory `raw`. The current notebook will extract the information necessary for an edge list that can be imported in [Gephi](https://gephi.org/). In addition, the code will create a node list with one attribute (`eponym`, either `True` or `False`). For importing these files into [Gephi](https://gephi.org/), see the bottom of this file.\n",
    "\n",
    "The first step is to select all proper names that appear in the letters. Two proper names that appear in the same letter represent an (undirected) edge. In a second step, this list of edges is augmented with catalog information such as sender location and dossier. In a third step the catalog is used to create additional (directed) edges, representing sender and recipient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mqCgZWhME-u"
   },
   "source": [
    "# 1 Creat Edge List from Proper Names in Letters\n",
    "\n",
    "First open the `.csv` file (prepared by parsing the corpus JSON files) and import it into a Pandas Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F6s6caXYME-w",
    "outputId": "289914f6-a267-499d-a2e2-b7714bd0cb90"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raw/sargonletters.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c40d253e0d6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raw/sargonletters.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'raw/sargonletters.csv'"
     ]
    }
   ],
   "source": [
    "with open(\"raw/sargonletters.csv\", mode = 'r', encoding = \"utf8\") as f:\n",
    "    df = pd.read_csv(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehUhEIEMME-7"
   },
   "source": [
    "Select the rows where `pos` is either `PN` (Personal Name) or `RN` (Royal Name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7fywqstkME-9"
   },
   "outputs": [],
   "source": [
    "keep = [\"PN\", \"RN\"]\n",
    "df = df[df[\"pos\"].isin(keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mR3B6sGwME_K"
   },
   "source": [
    "Select the columns `id_text` (the P number), and `cf` (Citation Form) and clean up the `id_text` column (keep only the P number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vV5sthWjME_M",
    "outputId": "2e326238-c982-4a76-ae55-4eda0e3bc596"
   },
   "outputs": [],
   "source": [
    "df = df[[\"id_text\", \"cf\"]]\n",
    "df[\"id_text\"] = [idt[-7:] for idt in df[\"id_text\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyzxgtcNME_S"
   },
   "source": [
    "Transform the Pandas Dataframe into a simple list of list. In order to produce the edge list we use a loop within a loop. The first loop goes through all the items in the list (all names). For each name, it goes through the entire list again, to find items that match the same text ID (P number). This way, the routine finds all pairs of names that appear in each letter.\n",
    "\n",
    "The secondary loop begins at the location of the index of the primary loop. This way, the edge A == B is not duplicated by the edge B == A (since the edges are undirected).\n",
    "\n",
    "If there is a text ID match in the secondary loop, make a list that contains `id_text`, `source`, and `target` - this list represents a single edge. Add this list to the list of lists `edges`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Wq_tp2GRME_U"
   },
   "outputs": [],
   "source": [
    "data = df.values.tolist()\n",
    "edges = []\n",
    "for idx, item in enumerate(data):\n",
    "    textid = item[0]\n",
    "    source = item[1]\n",
    "    for idx_2, item_2 in enumerate(data[idx:len(data)]):\n",
    "        if item[0] == item_2[0]:\n",
    "            if not item[1] == item_2[1]:\n",
    "                target = item_2[1]\n",
    "                edge = [textid, source, target]\n",
    "                edges.append(edge)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7GuoMaVME_e"
   },
   "source": [
    "The object `edges` is a list of list that can be transformed again into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OexnHj2VME_i",
    "outputId": "8a34b845-dcee-41c0-cc21-b5f035eb8f5c"
   },
   "outputs": [],
   "source": [
    "df_edges = pd.DataFrame(edges, columns= [\"id_text\", \"source\", \"target\"])\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MD87MuHpME_o"
   },
   "source": [
    "If the same name is mentioned multiple times in the same letter, that will create duplicate edges. Drop the duplicates.\n",
    "\n",
    "Add a new field, called `Type` to indicate whether an edge is directed or undirected. So far, all the edges are undirected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xSo2ifO_ME_p",
    "outputId": "d2ca4725-adfc-40ff-cddc-38f73ebbfd61"
   },
   "outputs": [],
   "source": [
    "df_edges = df_edges.drop_duplicates().reset_index(drop=True)\n",
    "df_edges[\"Type\"] = \"undirected\" \n",
    "df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYl8XPO9ME_v"
   },
   "source": [
    "# 2. Add Catalog Information to the Edge List\n",
    "The file `catalogue.json`, which is available in the file `jsonzip/saao-sargonletters.zip`, contains more information about each letter. The main field in `catalogue.json` is called `members` which contains the catalog information for each text in this corpus. We select a number of relevant catalog fields. We can add this information to the edge list by merging the two dataframes on `id_text` (the P number).\n",
    "\n",
    "Instead of extracting all the files from the `ZIP` file we can create a `ZipFile` object and then read only the file we need (namely `catalogue.json`). This is transformed into a `JSON` object which can be further manipulated and transformed into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "h4lpy6FyME_x",
    "outputId": "b5ed73aa-d398-43ef-9128-23e87e5a9cd7"
   },
   "outputs": [],
   "source": [
    "z = zipfile.ZipFile('jsonzip/saao-sargonletters.zip', 'r')\n",
    "data = z.read(\"saao/sargonletters/catalogue.json\").decode(\"utf-8\")\n",
    "data = json.loads(data)\n",
    "d = data['members']\n",
    "df = pd.DataFrame(d).T\n",
    "df_cat = df[[\"id_text\", \"ancient_author\", \"sender_title\", \"recipient\", \"senderloc\", \"dossier\"]]\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5e-5rK8ME_1"
   },
   "source": [
    "The names of author and recipient in the catalog are sometimes slightly different from the name forms in the lemmatization. The code in the following cell replaces the catalog form by the lemmatization form. The `.replace()` method in Pandas will search and replace a full string. In order to perform the search/replace on a partial string the option `regex = True` is necessary. Therefore, characters that have a special function in regular expressions (such as `[` and `(`) must be escaped by preceding them with a backslash.\n",
    "\n",
    "The search - replace pairs are listed in a dictionary that can be fed to the Pandas `.replace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QwbtZuzJME_3"
   },
   "outputs": [],
   "source": [
    "search_replace = {\"Ṭab-ṣill-Ešarra\": \"Ṭab-ṣil-Ešarra\",\n",
    "                  \"’\": \"ʾ\",\n",
    "                  \"\\[\": \"\",\n",
    "                  \"\\]\": \"\",\n",
    "                  \"Nashir-Bel \\(Liphur-Bel\\)\": \"Nashir-Bel\",\n",
    "                 \"Sennacherib\": \"Sin-ahhe-eriba\",\n",
    "                 \"Upaqa-Šamaš\" : \"Upaq-Šamaš\",\n",
    "                  }\n",
    "fields = [\"ancient_author\", \"recipient\"]\n",
    "df_cat[fields] = df_cat[fields].replace(search_replace, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_2hxZ6EME_6"
   },
   "source": [
    "Now merge the edges Dataframe with the catalog information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1qDVhdgoME__",
    "outputId": "e2015bf7-8aeb-4312-ccdd-0f2b440e96bc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_edges_cat = pd.merge(df_edges, df_cat, on=\"id_text\").fillna(\"\")\n",
    "with open(\"csv/edges_no_sender.csv\", mode=\"w\", encoding=\"utf-8\") as w:\n",
    "    df_edges_cat.to_csv(w, index=False)\n",
    "df_edges_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgR1HlAwMFAF"
   },
   "source": [
    "# 3. Add Sender and Recipient\n",
    "Neo-Assyrian letters to or from the king often do not contain the name of sender or recipient, because the king's name is never explicit. We can pull this information from the dataframe `df_cat` that we have created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jb3LNKGGMFAG",
    "outputId": "fbe4913a-e606-405b-f081-cb9067ac05cd"
   },
   "outputs": [],
   "source": [
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOmweOC3MFAM"
   },
   "source": [
    "Note that `ancient_author` sometimes has more than one name, separated by a comma. The code tests for the presence of a comma in the field `ancient author`. If a comma appears, the field is split at the comma, resulting in a list of authors (2 or more). For each author a separate row is created that copies the original row, but replaces the field `ancient_author` by the author. The same is done for recipients.\n",
    "\n",
    "### Note:\n",
    "It is necessary to use two separate `if/else` loops in order to take care of the possibility of multiple senders *and* multiple recipients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GInCcgA9MFAO"
   },
   "outputs": [],
   "source": [
    "cat = df_cat.values.tolist()\n",
    "cat_edges = []\n",
    "for item in cat:\n",
    "    if ',' in item[1]:\n",
    "        senders = item[1].split(',')\n",
    "        for sender in senders:\n",
    "            edge = item.copy()\n",
    "            edge[1] = sender.strip()\n",
    "            cat_edges.append(edge)\n",
    "    else:\n",
    "        cat_edges.append(item)\n",
    "cat_edges2 = []\n",
    "for item in cat_edges:\n",
    "    if ',' in item[3]:\n",
    "        recipients = item[3].split(',')\n",
    "        for recipient in recipients:\n",
    "            edge = item.copy()\n",
    "            edge[3] = recipient.strip()\n",
    "            cat_edges2.append(edge)\n",
    "    else:\n",
    "        cat_edges2.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OCGDfFFNMFAT",
    "outputId": "c592c4bb-606b-411b-b46d-bc42b49fed8f"
   },
   "outputs": [],
   "source": [
    "df_cat2 = pd.DataFrame(cat_edges2, columns = df_cat.columns)\n",
    "df_cat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaNhcbwLMFAX"
   },
   "source": [
    "Copy the columns `ancient_author` and `recipient` into `source` and `target`, respectively, and add `Type` to make the dataframe compatible with `df_edge_cat` created above. For this set of rows all the edges are Directed because they connect sender and recipient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "txl6ZDxEMFAa"
   },
   "outputs": [],
   "source": [
    "df_cat2[\"source\"] = df_cat2[\"ancient_author\"].copy()\n",
    "df_cat2[\"target\"] = df_cat2[\"recipient\"].copy()\n",
    "df_cat2[\"Type\"] = \"directed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVzMJqOVMFAg"
   },
   "source": [
    "Combine the two Dataframes; change all missing values into the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qYPG9a_eMFAi",
    "outputId": "517a2e1e-4711-40ba-cbe8-9b8c8843852c"
   },
   "outputs": [],
   "source": [
    "df_combined = df_edges_cat.append(df_cat2).reset_index(drop=True)\n",
    "df_combined = df_combined.fillna(\"\")\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XD0HAmxHMFAs"
   },
   "source": [
    "Write to a `CSV` file to be imported as an edge list in [Gephi](https://gephi.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3vBq6mvmMFAt"
   },
   "outputs": [],
   "source": [
    "with open(\"csv/edges.csv\", mode=\"w\", encoding=\"utf-8\") as w:\n",
    "    df_combined.to_csv(w, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUnoWRNZMFAw"
   },
   "source": [
    "# 4 Creat Node List\n",
    "[Gephi](https://gephi.org/) will automatically create a node list from the edge list. The advantage of explicitly adding a node list is that we can add one or more attributes to the nodes.\n",
    "\n",
    "First create the node list from the columns `source` and `target` in the `df_combined` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pwhgpFOzMFAx"
   },
   "outputs": [],
   "source": [
    "nodes = list(set(list(df_combined[\"source\"])) | set(list(df_combined[\"target\"])))\n",
    "df_nodes = pd.DataFrame(nodes, columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKlkN3eFMFA0"
   },
   "source": [
    "The file `sargoneponymns.csv` is a simple, one-dimensional list of names that match the names as they appear in the data set. Read the list of eponymns (or any other type of attribute) and add a column `eponym`. The value of each row in that column is set to be `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dg9YYudSMFA1"
   },
   "outputs": [],
   "source": [
    "with open(\"csv/sargoneponyms.csv\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    eponyms = pd.read_csv(f)\n",
    "eponyms[\"eponym\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKhG9tfLMFA3"
   },
   "source": [
    "Merge the `df_nodes` dataframe with the `eponymns` dataframe. The `outer` method keeps all rows of both dataframes and joins them where they match (in this case on `label`). The default behavior of `merge()` is to keep only those rows that match. Where there is no match (not an eponym) the `eponym` column will have `NaN` (\"Not a Number\", or missing value). These missing values are set to `False`.\n",
    "\n",
    "Copy the column `label` into a column `Id`. The `Id` column is used by Gephi to identify nodes; the `label` column is used to display labels in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "80t4a0hVMFA3",
    "outputId": "3239cd4f-3ba4-4db0-8084-9067c76267b2"
   },
   "outputs": [],
   "source": [
    "df = df_nodes.merge(eponyms, on = \"label\", how=\"outer\")\n",
    "df[\"eponym\"] = df[\"eponym\"].fillna(False)\n",
    "df[\"Id\"] = df[\"label\"].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyjx4GtOMFA5"
   },
   "source": [
    "Save the nodes list as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0wFKsXtkMFA6"
   },
   "outputs": [],
   "source": [
    "with open(\"csv/nodes.csv\", mode=\"w\", encoding=\"utf-8\") as w:\n",
    "    df.to_csv(w, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-KP9dLFMFA9"
   },
   "source": [
    "# 5 Import in [Gephi](https://gephi.org/)\n",
    "First, import the node list (go to Data Laboratory and click on `import spreadsheet`). After importing, copy the `Id` column to the `Label` column. Now import the edge list. The order of import is important. When you import an edge list, [Gephi](https://gephi.org/) will add all non-existent nodes to the node list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mO6APkulMFA_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "make_edge_node_list.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
