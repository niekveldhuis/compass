{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2 Retrieve ORACC Catalog Data\n",
    "\n",
    "In this section we will download one or more [ORACC](http://oracc.org) projects, select the catalog data and display the catalog in a table. Each [ORACC](http://oracc.org) JSON `zip` file includes a file named `catalogue.json`. \n",
    "\n",
    ":::{margin}\n",
    "For general information, see the [Oracc Open Data](http://oracc.org/doc/opendata) page.\n",
    ":::\n",
    "\n",
    "The file `catalogue.json` contains all the catalog data for an [ORACC](http://oracc.org) project. We will transform the JSON into a `pandas` dataframe. \n",
    "\n",
    ":::{note}\n",
    "A dataframe is, essentially, a table in which each row represents an observation (in our case: a document) and each column represents an attribute (publication, museum number, etc.). \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2.0 Load Packages\n",
    "* pandas: data analysis and manipulation; dataframes\n",
    "* ipywidgets: user interface (enter project names)\n",
    "* zipfile: read data from a zipped file\n",
    "* json: read a json object\n",
    "* os: basic Operating System tasks (such as creating a directory)\n",
    "* sys: change system parameters\n",
    "* utils: compass-specific utilities (download files from ORACC, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "util_dir = os.path.abspath('../utils')\n",
    "sys.path.append(util_dir)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2.1 Create Directories, if Necessary\n",
    "The two directories needed for this script are `jsonzip` and `output`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('jsonzip', exist_ok = True)\n",
    "os.makedirs('output', exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2.2 Input Project Names\n",
    "We can download and manipulate multiple [ORACC](http://oracc.org) `zip` files at the same time. The `Textarea` widget provides a space for typing project abbreviations, separated by a comma. The widget is assigned to the variable `projects`. The text entered in the `Textarea` widget can be retrieved as `projects.value`.\n",
    "\n",
    ":::{warning}\n",
    "Subprojects must be listed separately, they are not included in the main project. A subproject is named `[PROJECT]/[SUBPROJECT]`, for instance `saao/saa01`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fa18d8b77e41ac8969508c12fa665a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='obmc', description='Projects:', placeholder='Type project names, separated by commas')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "projects = widgets.Textarea(\n",
    "    value=\"obmc\",\n",
    "    placeholder='Type project names, separated by commas',\n",
    "    description='Projects:',\n",
    ")\n",
    "projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2.3 Split the List of Projects and Download the ZIP files.\n",
    "Use the `format_project_list()` and `oracc_download()` functions from the `utils` module to download the requested projects. The code of these function is discussed in more detail in 2.1.0. Download ORACC JSON Files. The function returns a new version of the project list, with duplicates and non-existing projects removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving http://oracc.org/saao/saa01/json/saao-saa01.zip as jsonzip/saao-saa01.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niek\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'oracc.museum.upenn.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee70541223444cefb390abb18fd04b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "saao/saa01: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_list = utils.format_project_list(projects.value)\n",
    "project_list = utils.oracc_download(project_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2.4 Extract Catalogue Data from `JSON` files\n",
    "The process begins by turning a `zip` file (for instance `obmc.zip`) into a `zipfile` object that may be manipulated with the functions available in the `zipfile` library. This is done with the `zipfile.Zipfile()` function:\n",
    "\n",
    "```python\n",
    "import zipfile\n",
    "file = \"jsonzip/obmc.zip\"    \n",
    "# or: file = \"jsonzip/dcclt-nineveh.zip\"\n",
    "zipfile_object = zipfile.ZipFile(file)\n",
    "```\n",
    "\n",
    "The `read()` function from that same `zipfile` package reads one particular file from the `zip` and turns it into a string:\n",
    "\n",
    "```python\n",
    "string_object = zipfile_object.read(\"obmc/catalogue.json\").decode(\"utf-8\") \n",
    "# or: string_object = zipfile_object.read(\"dcclt/nineveh/catalogue.json\").decode(\"utf-8\")\n",
    "```\n",
    "\n",
    "The `json` library provides functions for reading (loading) or producing (dumping) a JSON file. Reading is done with the function `load()`, which comes in two versions. Regular `json.load()` takes a filename as argument and will load a JSON file. In this case, however, the `read()` function from the `zipfile` library has produced a string (extracted from `obmc.zip`), and therefore we need the command `json.loads()`, which takes a string as its argument:  \n",
    "\n",
    "```python\n",
    "import json\n",
    "json_object = json.loads(string_object)\n",
    "```\n",
    "\n",
    "The variable `json_object` will now contain all the data in the `catalogue.json` file from the [OBMC](http://oracc.org/obmc) (Old Babylonian Model Contracts) project by Gabriella Spada. We may treat the variable `json_object` as a Python dictionary. The `catalogue.json` has various keys, including `type`, `project`, `source`, `license`, `license-url`, `more-info`, `UTC-timestamp`, `members`, and `summaries`. The key `members` is the only one that concerns us here, since it contains the actual catalog information. The value of the key `members` is itself a dictionary of dictionaries. Each of the keys in the top-level dictionary is a P, Q, or X-number (a text ID). The value of each of these keys is still another dictionary; each key in that dictionary is a field in the original catalog (`primary_publication`, `provenience`, `genre`, etc.). The dictionary of dictionaries under the key `members` may be transformed into a Pandas dataframe for ease of viewing and manipulation.\n",
    "\n",
    "``` python\n",
    "import pandas as pd\n",
    "cat = json_object[\"members\"]\n",
    "df = pd.DataFrame.from_dict(cat)\n",
    "df\n",
    "```\n",
    "\n",
    "By default, the `DataFrame.from_dict()` function in the `pandas` library takes each key as a column - in this case the keys of `cat` are the P numbers (text IDs); the catalog fields will become rows. To address that issue, we need to tell the `DataFrame.from_dict()` function explicitly that each key should be a row (`orient=\"index\"`) \n",
    "\n",
    "```python\n",
    "df = pd.DataFrame.from_dict(cat, orient=\"index\")\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put the code discussed above in a loop that will iterate through the list of projects entered in 2.1.2.2. For each project the `JSON` zip file, named `[PROJECT].zip` has been downloaded in the directory `jsonzip`. \n",
    "\n",
    "In the last step of the loop, the individual dataframes (one for each project requested) are concatenated. Since individual [ORACC](http://oracc.org) project catalogs may have different fields, the dataframes may have different column names. By default `pandas` concatenation uses an `outer join` so that all column names of all the catalogs are preserved.\n",
    "\n",
    ":::{warning}\n",
    "[ORACC](http://oracc.org) catalogs have two obligatory fields: `id_text` (the P, Q, or X number that identifies the text, for instance \"P243546\") and `designation` (the human-readable reference, for instance \"MEE 04, 020\"). Many projects use catalog fields that are derived from [CDLI](http://cdli.ucla.edu), such as `museum_no`, `primary_publication`, etc., but there is no uniformity. If you build a catalog from multiple projects you may need to manipulate the resulting dataframe to align the catalogs.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() # create an empty dataframe\n",
    "for project in project_list:\n",
    "    file = f\"jsonzip/{project.replace('/', '-')}.zip\"\n",
    "    try:\n",
    "        zip_file = zipfile.ZipFile(file)       # create a Zipfile object\n",
    "    except:\n",
    "        errors = sys.exc_info() # get error information\n",
    "        print(file), print(errors[0]), print(errors[1]) # and print it\n",
    "        continue\n",
    "    try:\n",
    "        json_cat_string = zip_file.read(f\"{project}/catalogue.json\").decode('utf-8')  #read and decode the catalogue.json file of one project\n",
    "                                                                # the result is a string object\n",
    "    except:\n",
    "        errors = sys.exc_info() # get error information\n",
    "        print(project), print(errors[0]), print(errors[1]) # and print it\n",
    "        continue\n",
    "    zip_file.close()\n",
    "    cat = json.loads(json_cat_string)\n",
    "    cat = cat['members']  # select the 'members' node \n",
    "    cat_df = pd.DataFrame.from_dict(cat, orient=\"index\")\n",
    "    cat_df[\"project\"] = project  # add project name as separate field\n",
    "    df = pd.concat([df, cat_df], sort=True)  # sort=True is necessary in case catalogs have different sets of fields\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2.5 Clean the Dataframe\n",
    "The function `fillna('')` will put a blank (instead of `NaN`) in all fields that have no entry.\n",
    "\n",
    ":::{note}\n",
    "NaN means \"Not a Number\" and is used for missing values. NaN is a special data type (it is not equivalent to the string \"NaN\"!) and may cause a number of issues in manipulating the dataframe.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2.1.2.6)=\n",
    "## 2.1.2.6 Select Relevant Fields\n",
    ":::{margin}\n",
    "Various introductions to Pandas may be found on the web or in [VanderPlas 2016](https://github.com/jakevdp/PythonDataScienceHandbook) and similar overviews.\n",
    ":::\n",
    "\n",
    "The Pandas library allows one to manipulate and slice a dataframe in many different ways. The example code below assigns to the variable `keep` a list of the most relevant fields (these are field names that are available in (almost) every [ORACC](http://oracc.org) catalog). The list `keep` is used to create a new dataframe, with only the relevant fields. Adjust the code to your data and your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['designation', 'period', 'provenience',\n",
    "        'museum_no', 'project', 'id_text']\n",
    "df1 = df[keep]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2.7 Save as CSV\n",
    ":::{margin}\n",
    "Character encoding is primarily relevant when reading from or writing to disk. See section 1.4.4.\n",
    ":::\n",
    "\n",
    "Save the resulting data set as a `csv` file. `UTF-8` encoding is the encoding with the widest support in text analysis and the standard encoding in Python. It is also the encoding used by [ORACC](http://oracc.org). \n",
    "\n",
    ":::{note}\n",
    "If you intend to use the catalog file in Excel, it is better to use `utf-16` encoding.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'output/catalog.csv'\n",
    "df1.to_csv(filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2.8 Save with Pickle\n",
    "One may pickle a file either with the `pickle` library or directly from within `pandas` library with the `to_pickle()` function. A pickled file preserves the data structure of the dataframe, which is an advantage over saving as `csv`. The pickle file is a binary file, so we must open the file with the `wb` (write binary) option and we cannot give an encoding. \n",
    "\n",
    ":::{note}\n",
    "To open the pickled file again:\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('output/catalog.p)\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"output/catalog.p\"\n",
    "df1.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
