{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Data Acquisition from CDLI\n",
    "## 2.3.1 Introduction: CDLI data\n",
    "The [Cuneiform Digital Library Initiative](http://cdli.ucla.edu), created by [Bob Englund](https://cdli.ucla.edu/?q=robert-k-englund) (UCLA) in the early two thousands, is a central repository for meta-data, images, and transliterations of cuneiform objects (translations are offered only for a small minority of texts). Today more than 335,000 objects are listed in the [CDLI](http://cdli.ucla.edu) catalog, with tens of thousands of photographs and line drawings. Each object in [CDLI](http://cdli.ucla.edu) receives a unique ID number, and these numbers are widely used today in print and in on-line projects. Initially, [CDLI](http://cdli.ucla.edu) focused primarily on administrative texts from the third millennium, and this is still the area of its greatest strength. Currently, approximately 121,000 texts are available in transliteration in [CDLI](http://cdli.ucla.edu). Part of this corpus was produced by the [CDLI](http://cdli.ucla.edu) team at UCLA, others were contributed by partners or were imported from other projects such as [ETCSL](https://etcsl.orinst.ox.ac.uk/) (for Sumerian literary texts), [DCCLT](http://oracc.org/dcclt) (for lexical texts), or [BDTNS](http://bdtns.filol.csic.es/) (for Ur III administrative texts). The photographs on [CDLI](http://cdli.ucla.edu) were largely produced in cooperative projects with museums all over the world, where [CDLI](http://cdli.ucla.edu) staff or partners would go to scan an entire collection or major parts of a collection. These images are copyright of the museum where the object is held and there is no wholesale downloading of the entire image set.\n",
    "\n",
    "```{figure} ../images/Robert+Englund.jpg\n",
    ":figclass: margin\n",
    ":scale: 25%\n",
    "\n",
    "[Bob Englund](https://cdli.ucla.edu/?q=news/obituary-robert-k-englund) 1952-2020\n",
    "```\n",
    "\n",
    "```{figure} ../images/cdli_logo.gif\n",
    ":figclass: margin\n",
    ":scale: 50%\n",
    "```\n",
    "\n",
    "The [CDLI](http://cdli.ucla.edu) project transformed the practice of Assyriology in multiple ways. The availability of large numbers of photographs made it much easier to collate problematic passages in texts only published in transliteration and/or hand drawing. Issuing ID numbers made it easier to refer to a particular tablet while avoiding the confusion of obscure publication abbreviations and museum numbers. The spread of all this information on the web made it available everywhere where one can access the internet.\n",
    "\n",
    "For each cuneiform object the [CDLI](http://cdli.ucla.edu) catalog provides information about where it was published (and by whom), in which collection it is kept, where it was excavated, to which period it belongs, what textual genre it represents, etc. In addition, an object may be represented by one or more images (photographs and/or hand drawings) and by a transliteration. Several of the fields in the [CDLI](http://cdli.ucla.edu) catalog either use a restricted vocabulary (period, genre) or have been standardized to a great degree (provenance, author's name, owner, museum number), greatly facilitating search. \n",
    "\n",
    ":::{margin}\n",
    "For the readings introduced by P. Attinger, see the introduction to his [Glossaire sumérien–français](https://www.harrassowitz-verlag.de/isbn_9783447116169.ahtml).\n",
    ":::\n",
    "\n",
    "The issue of standardization is much more difficult for linguistic data in transliteration. Here, Sumerian and Akkadian pose rather different challenges. For Sumerian, there are two main issues. First, Sumerologists tend to use different sets of conventions for representing Sumerian words in the Latin alphabet. The word for \"to give\" is read [**šum₂**](http://oracc.org/epsd2/o0039914) by some, but **sum** by others. Similarly, the word for \"ox\" is read either [**gud**](http://oracc.org/epsd2/o0028670) or **gu₄**. These readings (**šum₂** vs **sum** or **gud** vs. **gu₄**) represent the same word and render the same sign - they simply differ in modern transliteration conventions. Variation in such conventions has grown recently by the introduction of a new set of readings by P. Attinger (Bern), which has received wide following, in particular in Germany. Such variation in sign readings is based on the one hand on differing interpretations of the data from [ancient sign lists](http://oracc.org/dcclt/signlists) (which provide transcriptions of Sumerian words in Akkadian) and on the other hand on the definition of what an ideal transliteration should do (whether it should represent the abstract lexeme, or rather its concrete pronunciation, or something in between). For the [CDLI](http://cdli.ucla.edu) search engine, which is based on a FileMaker database, such variation presents a problem when searching for (Sumerian) words. The solution has been to strictly impose a set of [preferred sign readings](https://cdli.ucla.edu/methods/sign_reading.html), a policy that has been carried out with great consistency. \n",
    "\n",
    "Second, Sumerian has no good standard for word segmentation. In the [CDLI](http://cdli.ucla.edu) data set one may find the word [**ninda-i₃-de₂-a**](http://oracc.org/epsd2/o0036259) (a pastry) transliterated as **ninda-i₃-de₂-a**, **ninda i₃-de₂-a**, **ninda i₃ de₂-a**, **nig₂-i₃-de₂-a**, **nig₂ i₃ de₂-a**, etcetera (**nig₂** and **ninda** are two different words, written by the same sign and there is no full agreement which of these is to be used in this particular expression). None of these various renderings is necessarily \"wrong\", because we know fairly little about the formation and segmentation of Sumerian nouns. For computational approaches this variation poses an important challenge.\n",
    "\n",
    "For Akkadian the variation in reading conventions plays a much smaller role; for most dialects of Akkadian (with the exception of Old Akkadian) scholars generally agree on transliteration conventions; word segmentation is hardly ever a problem. For search engines, however, Akkadian transliteration is much more difficult to deal with because the same word may be spelled in many different ways. Without lemmatization, there is no way a machine can tell that ***ša-ar-ru-um***, ***ša-ar-ri-im***, ***ša-ar-ra-am***, ***šar-ru***, ***šar-ri***, ***šar-ra***, **LUGAL**, and **MAN** all represent the same word for \"king\" in syllabic and logographic writing. The rich morphology of Akkadian, with prefixes, suffixes, and infixes and various vowel patterns to be applied to different forms of a single verb further complicates this issue.\n",
    "\n",
    "Since [CDLI](http://cdli.ucla.edu) does not offer lemmatization, searching for words on this site is much more popular (and more useful) for Sumerian than it is for Akkadian. Sumerian words usually include the root of the word (written logographically) with prefixes and/or suffixes attached. Although spelling variations exist (e.g. **dag-si**, **da-ag-ši-um**, and **da-ag-zi-um**, all representing variants of the word [dagsi](http://oracc.org/epsd2/o0025593) for saddle hook or saddle bag), such variation plays a much smaller role in Sumerian than in Akkadian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2 Downloading CDLI data\n",
    "\n",
    "There are various ways in which one can acquire [CDLI](http://cdli.ucla.edu) data. The website includes a [Downloads](https://cdli.ucla.edu/?q=downloads) page where one can get access to a daily clone of the catalog and the entire set of transliterations. Alternatively, one can perform a search on the [CDLI](http://cdli.ucla.edu) search page and request a download of the data (transliteration or catalog and transliteration data) by pushing a button. This works well for a few or several dozens of texts, but not for very large data sets. The present notebook will download the [CDLI](http://cdli.ucla.edu) files from the daily clone on [Github](https://github.com/cdli-gh/data).\n",
    "\n",
    "Currently, the set of transliterations is offered in one big file, named `cdliatf_unblocked.atf `. The catalog is split into two files because of file-size limitations at [Github](http://github.com); they are named `cdli_catalogue_1of2.csv` and `cdli_catalogue_2of2.csv`, respectively. The files need to be concatenated before they can be used.\n",
    "\n",
    "### 2.3.2.0 Import Packages\n",
    "* requests: for communicating with a server over the internet\n",
    "* tqdm: for creating progress bars\n",
    "* pandas: data analysis and manipulation; dataframes\n",
    "* BeautifulSoup: web scraping\n",
    "* os: for basic Operating System operations (such as creating a directory)\n",
    "* shutil: file operations (such as concatenating files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2.1 Create Download Directory\n",
    "Create a directory called `cdlidata`. If the directory already exists, do nothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('cdlidata', exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2.2 Retrieve File Names\n",
    "We first need to retrieve the names of the files that are offered for download on the CDLI [download](https://github.com/cdli-gh/data) page on GitHub. The script requests the HTML of the download page and uses [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) (a package for web scraping) to retrieve all the links from the page. This includes the file names, but also all kinds of other links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cdli_catalogue_1of2.csv', 'cdli_catalogue_2of2.csv', 'cdliatf_unblocked.atf'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_page = \"https://github.com/cdli-gh/data\"\n",
    "r = requests.get(download_page)\n",
    "html = r.text\n",
    "soup = BeautifulSoup(html)\n",
    "links = soup.find_all('a')       # retrieve all html anchors, which define links\n",
    "files = set()\n",
    "for link in links:\n",
    "    f = link.get('href')        # from the anchors, retrieve the URLs\n",
    "    files.add(f)\n",
    "files = {f for f in files if 'master/cdli' in f}  # filter out the relevant URLs\n",
    "files = {f.split('/')[-1] for f in files} # only keep the file names (without the path)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2.3 Download\n",
    "The download code in this cell is essentially identical with the code in section [2.1.0](2.1.0): Download ORACC JSON. Depending on the speed of your computer and internet connection the downloading process can take some time because of the size of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving https://raw.github.com/cdli-gh/data/master/cdli_catalogue_2of2.csv as cdlidata/cdli_catalogue_2of2.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb98cb6e6204c6ea1fda783bfdada67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cdli_catalogue_2of2.csv:   0%|          | 0.00/6.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving https://raw.github.com/cdli-gh/data/master/cdli_catalogue_1of2.csv as cdlidata/cdli_catalogue_1of2.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccc57b2e87c4dde8c786e99b804787e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cdli_catalogue_1of2.csv:   0%|          | 0.00/7.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving https://raw.github.com/cdli-gh/data/master/cdliatf_unblocked.atf as cdlidata/cdliatf_unblocked.atf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f2c5b4317b4eb2899e8bfd6e683f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cdliatf_unblocked.atf:   0%|          | 0.00/20.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CHUNK = 1024\n",
    "for file in files:\n",
    "    url = f\"https://raw.github.com/cdli-gh/data/master/{file}\"\n",
    "    target = f'cdlidata/{file}'\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        if r.status_code == 200:\n",
    "            total_size = int(r.headers.get('content-length', 0))\n",
    "            tqdm.write(f'Saving {url} as cdlidata/{file}')\n",
    "            t=tqdm(total=total_size, unit='B', unit_scale=True, desc = file)\n",
    "            with open(target, 'wb') as f:\n",
    "                for c in r.iter_content(chunk_size=CHUNK):\n",
    "                    t.update(len(c))\n",
    "                    f.write(c)\n",
    "        else:\n",
    "            print(f\"{url} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2.4. Concatenate the Catalogue Files\n",
    "The catalogue files are concatenated, using a utility from the `shutil` package. The new, concatenated, file is called `catalogue.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f for f in files if \"cdli_catalogue\" in f]\n",
    "filenames.sort()  # to make sure we read cdli_catalogue_1of2.csv first.\n",
    "with open('cdlidata/catalogue.csv','wb') as concatenated_file:\n",
    "    for file in filenames:\n",
    "        with open(f'cdlidata/{file}','rb') as one_file:\n",
    "            shutil.copyfileobj(one_file, concatenated_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2.4 Load in a Pandas data frame\n",
    "\n",
    "The field `id_text` holds the text ID number as a string, without the preceding \"P\" and without padding zeroes to the left. The text ID \"P001023\" is thus represented as 1023. When reading the data into `pandas`, chances are that the data type of `id_text` is interpreted as integer. The function `zfill()` adds the padding zeros to create a six-digit number as a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession_no</th>\n",
       "      <th>accounting_period</th>\n",
       "      <th>acquisition_history</th>\n",
       "      <th>alternative_years</th>\n",
       "      <th>ark_number</th>\n",
       "      <th>atf_source</th>\n",
       "      <th>atf_up</th>\n",
       "      <th>author</th>\n",
       "      <th>author_remarks</th>\n",
       "      <th>cdli_collation</th>\n",
       "      <th>...</th>\n",
       "      <th>seal_information</th>\n",
       "      <th>stratigraphic_level</th>\n",
       "      <th>subgenre</th>\n",
       "      <th>subgenre_remarks</th>\n",
       "      <th>surface_preservation</th>\n",
       "      <th>text_remarks</th>\n",
       "      <th>thickness</th>\n",
       "      <th>translation_source</th>\n",
       "      <th>width</th>\n",
       "      <th>object_remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>21198/zz001q0dtm</td>\n",
       "      <td>Englund, Robert K.</td>\n",
       "      <td></td>\n",
       "      <td>CDLI</td>\n",
       "      <td>31x61x18; Lú A 14-16.30-32.48-50; M XVIII, auf...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Archaic Lu2 A (witness)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>no translation</td>\n",
       "      <td>61</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>21198/zz001q0dv4</td>\n",
       "      <td>Englund, Robert K.</td>\n",
       "      <td></td>\n",
       "      <td>CDLI</td>\n",
       "      <td>30x48x13; Lú A 13-15.23-25.?; Fundstelle wie W...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Archaic Lu2 A (witness)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>no translation</td>\n",
       "      <td>48</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>21198/zz001q0dwn</td>\n",
       "      <td>Englund, Robert K.</td>\n",
       "      <td></td>\n",
       "      <td>Englund, Robert K. &amp; Nissen, Hans J.</td>\n",
       "      <td>42x53x19; Vocabulary 9; Qa XVI,2, unter der Ab...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Archaic Vocabulary (witness)</td>\n",
       "      <td>Text category: 15-09; Foreign ID: LVO 9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>no translation</td>\n",
       "      <td>53</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>21198/zz001q0dx5</td>\n",
       "      <td>Englund, Robert K.</td>\n",
       "      <td></td>\n",
       "      <td>CDLI</td>\n",
       "      <td>26x23x23; Lú A 9-10.?.?; Fundstelle wie W 9123...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Archaic Lu2 A (witness)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23</td>\n",
       "      <td>no translation</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>21198/zz001q0dzp</td>\n",
       "      <td>Englund, Robert K.</td>\n",
       "      <td></td>\n",
       "      <td>CDLI</td>\n",
       "      <td>29x36x20; Lú A Vorläufer; Qa XVI,2, unter der ...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Archaic Lu2 A (witness)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>no translation</td>\n",
       "      <td>36</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344796</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Jagersma, Bram</td>\n",
       "      <td></td>\n",
       "      <td>Langdon, Stephen H.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no translation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344797</th>\n",
       "      <td>00109</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Jagersma, Bram</td>\n",
       "      <td></td>\n",
       "      <td>Goetze, Albrecht</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no translation</td>\n",
       "      <td></td>\n",
       "      <td>unopened envelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344798</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no atf</td>\n",
       "      <td></td>\n",
       "      <td>Janssen, Caroline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no translation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344799</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no atf</td>\n",
       "      <td></td>\n",
       "      <td>Janssen, Caroline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no translation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344800</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no atf</td>\n",
       "      <td></td>\n",
       "      <td>Fish, Thomas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no translation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344801 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accession_no accounting_period acquisition_history alternative_years  \\\n",
       "0                                                                             \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "...             ...               ...                 ...               ...   \n",
       "344796                                                                        \n",
       "344797        00109                                                           \n",
       "344798                                                                        \n",
       "344799                                                                        \n",
       "344800                                                                        \n",
       "\n",
       "              ark_number          atf_source atf_up  \\\n",
       "0       21198/zz001q0dtm  Englund, Robert K.          \n",
       "1       21198/zz001q0dv4  Englund, Robert K.          \n",
       "2       21198/zz001q0dwn  Englund, Robert K.          \n",
       "3       21198/zz001q0dx5  Englund, Robert K.          \n",
       "4       21198/zz001q0dzp  Englund, Robert K.          \n",
       "...                  ...                 ...    ...   \n",
       "344796                        Jagersma, Bram          \n",
       "344797                        Jagersma, Bram          \n",
       "344798                                no atf          \n",
       "344799                                no atf          \n",
       "344800                                no atf          \n",
       "\n",
       "                                      author  \\\n",
       "0                                       CDLI   \n",
       "1                                       CDLI   \n",
       "2       Englund, Robert K. & Nissen, Hans J.   \n",
       "3                                       CDLI   \n",
       "4                                       CDLI   \n",
       "...                                      ...   \n",
       "344796                   Langdon, Stephen H.   \n",
       "344797                      Goetze, Albrecht   \n",
       "344798                     Janssen, Caroline   \n",
       "344799                     Janssen, Caroline   \n",
       "344800                          Fish, Thomas   \n",
       "\n",
       "                                           author_remarks cdli_collation  ...  \\\n",
       "0       31x61x18; Lú A 14-16.30-32.48-50; M XVIII, auf...                 ...   \n",
       "1       30x48x13; Lú A 13-15.23-25.?; Fundstelle wie W...                 ...   \n",
       "2       42x53x19; Vocabulary 9; Qa XVI,2, unter der Ab...                 ...   \n",
       "3       26x23x23; Lú A 9-10.?.?; Fundstelle wie W 9123...                 ...   \n",
       "4       29x36x20; Lú A Vorläufer; Qa XVI,2, unter der ...                 ...   \n",
       "...                                                   ...            ...  ...   \n",
       "344796                                                                    ...   \n",
       "344797                                                                    ...   \n",
       "344798                                                                    ...   \n",
       "344799                                                                    ...   \n",
       "344800                                                                    ...   \n",
       "\n",
       "       seal_information stratigraphic_level                      subgenre  \\\n",
       "0                                                 Archaic Lu2 A (witness)   \n",
       "1                                                 Archaic Lu2 A (witness)   \n",
       "2                                            Archaic Vocabulary (witness)   \n",
       "3                                                 Archaic Lu2 A (witness)   \n",
       "4                                                 Archaic Lu2 A (witness)   \n",
       "...                 ...                 ...                           ...   \n",
       "344796                                                                      \n",
       "344797                                                                      \n",
       "344798                                                                      \n",
       "344799                                                                      \n",
       "344800                                                                      \n",
       "\n",
       "                               subgenre_remarks surface_preservation  \\\n",
       "0                                                                      \n",
       "1                                                                      \n",
       "2       Text category: 15-09; Foreign ID: LVO 9                        \n",
       "3                                                                      \n",
       "4                                                                      \n",
       "...                                         ...                  ...   \n",
       "344796                                                                 \n",
       "344797                                                                 \n",
       "344798                                                                 \n",
       "344799                                                                 \n",
       "344800                                                                 \n",
       "\n",
       "       text_remarks thickness translation_source width     object_remarks  \n",
       "0                          18     no translation    61                     \n",
       "1                          13     no translation    48                     \n",
       "2                          19     no translation    53                     \n",
       "3                          23     no translation    23                     \n",
       "4                          20     no translation    36                     \n",
       "...             ...       ...                ...   ...                ...  \n",
       "344796                            no translation                           \n",
       "344797                            no translation        unopened envelope  \n",
       "344798                            no translation                           \n",
       "344799                            no translation                           \n",
       "344800                            no translation                           \n",
       "\n",
       "[344801 rows x 64 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = pd.read_csv('cdlidata/catalogue.csv', engine='python', error_bad_lines=False).fillna('')\n",
    "cat['id_text'] = [\"P\" + str(no).zfill(6) for no in cat['id_text']]\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.3 Use the Catalog to Select Transliterations\n",
    "In the example code in the following cell the catalog is used to select from the transliteration file all texts from the Early Dynastic IIIa period. The field \"period\" is used to select those catalog entries that have \"ED IIIa\" in that field. \n",
    "\n",
    "In the transliteration file, a new text is introduced by a line that begins with an ampersand (&) followed by a P number, followed by a publication reference (journal or book) using a commonly used set of abbreviations, as in:\n",
    "\n",
    "> \t&P212416 = AAICAB 1/1, pl. 008, 19282-439\n",
    "\n",
    "The set of transliterations in the file `cdliatf_unblocked.atf` is read into a list, one line at a time, with the `readlines()` method. The code iterates through that list of lines. The flag `keep` (which initially is set to `False`) is set to `True` if the code encounters a P number that is present in the list `pnos`. As long as `keep = True` subsequent lines are added to the list `ed3a_atf`. When the script encounters a P-number that is not in `pnos`, the flag `keep` is set to `False`.\n",
    "\n",
    "The result is a of list lines with all the transliteration data of the Early Dynastic IIIa texts in [CDLI](http://cdli.ucla.edu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c0e1ea6c7b4b9c937e4985e6355744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3432432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ed3a = cat.loc[cat[\"period\"].str[:7] == \"ED IIIa\"]\n",
    "pnos = list(ed3a[\"id_text\"])\n",
    "#pnos = [\"P\" + str(no).zfill(6) for no in pnos]\n",
    "with open(\"cdlidata/cdliatf_unblocked.atf\", encoding=\"utf8\") as c: \n",
    "    lines = c.readlines()\n",
    "keep = False\n",
    "ed3a_atf = []\n",
    "for line in tqdm(lines):\n",
    "    if line[0] == \"&\": \n",
    "        if line[1:8] in pnos: \n",
    "            keep = True\n",
    "        else: \n",
    "            keep = False\n",
    "    if keep: \n",
    "        ed3a_atf.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.4 Create a Data Frame with the Selected Texts\n",
    "The following code will transform the list `ed3a_atf` into a format where each text is a row in a `pandas` data frame, with the text ID in column 1, and the transliteration in column 2 (as a single string, without line numbers or line demarcations). This is, of course, just one example of how the data may be selected and formatted - we can use all the power of the `pandas` library to slice and manipulated the data.\n",
    "\n",
    "```{figure} ../images/P212416.jpg\n",
    ":scale: 25%\n",
    "[P212416](http://cdli.ucla.edu/P212416), an ED IIIa administrative document from Kish\n",
    "```\n",
    "\n",
    "The lines are read in reverse order, so that when the script encounters an '&P' line (as in '&P212416 = AAICAB 1/1, pl. 008, 19282-439'), this signals that all the lines of a text have been read and that the document can be added to the list `docs`. (When reading the lines in regular order - taking the '&P' line as signaling the end of the previous document - one needs to separately save the last document, because there is no '&P' line anymore to indicate that the text is complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543b6a272982415d922cd0fce21bfe84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = []\n",
    "document = ''\n",
    "id_text = ''\n",
    "ed3a_atf = [line for line in ed3a_atf if line.strip()]  # remove empty lines, which cause trouble\n",
    "for line in tqdm(reversed(ed3a_atf)):\n",
    "    if line[0] == \"&\":  # line beginning with & marks the beginning of a document\n",
    "        id_text = line[1:8] # retrieve the P number\n",
    "        docs.append([id_text, document])\n",
    "        document = ''   # after appending the data to docs, reset the variable `document`.\n",
    "        continue\n",
    "    elif line [0] in [\"#\", \"$\", \"<\", \">\", \"@\"]:  # skip all non-transliteration lines\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            line = line.split(' ', 1)[1].strip() # split line at first space (after the line number)\n",
    "            document = f'{line} {document}' # add the new line in front\n",
    "        except:\n",
    "            continue   # malformed lines (no proper separation between line number and text) are skipped\n",
    "ed3a_df = pd.DataFrame(docs)\n",
    "ed3a_df.columns = [\"id_text\", \"transliteration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_text</th>\n",
       "      <th>transliteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P306736</td>\n",
       "      <td>[x e2] sar [n] ku3 ma-na sa10#-bi 1(u@c) ku3 g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P010800</td>\n",
       "      <td>1(asz@c) HUL?-x 1(asz@c)#? ESZ#-ga-x? 1(asz@c)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P010644</td>\n",
       "      <td>LAK358-nu-ru gir2 AB si urin am6-dar sza3 ku3-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P519406</td>\n",
       "      <td>1(u@c) ku3 luh-ha gin2 sa10 e2 2(asz@c) e2-bi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P519401</td>\n",
       "      <td>[...] x [...] [...] x [...] x-gal# [...] tu7(|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>P010012</td>\n",
       "      <td>1(esze3@c) GAN2 ur-{d}nin-PA-ke4 lugal-USZ-MUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>P010011</td>\n",
       "      <td>6(asz@c) uruda ma-na sa10 GAN2 4(iku@c) GAN2-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>P010009</td>\n",
       "      <td>[6(asz@c)] uruda ma-na sa10 GAN2 4(iku@c) GAN2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>P010008</td>\n",
       "      <td>4(iku@c) GAN2 DUR2-HAR sar 1(u@c) uruda &lt;a&gt;-ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>P005984</td>\n",
       "      <td>[n] 4(bur3@c) _GAN2_ E2#? HA? GU4? x in ur-sa6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_text                                    transliteration\n",
       "0     P306736  [x e2] sar [n] ku3 ma-na sa10#-bi 1(u@c) ku3 g...\n",
       "1     P010800  1(asz@c) HUL?-x 1(asz@c)#? ESZ#-ga-x? 1(asz@c)...\n",
       "2     P010644  LAK358-nu-ru gir2 AB si urin am6-dar sza3 ku3-...\n",
       "3     P519406  1(u@c) ku3 luh-ha gin2 sa10 e2 2(asz@c) e2-bi ...\n",
       "4     P519401  [...] x [...] [...] x [...] x-gal# [...] tu7(|...\n",
       "...       ...                                                ...\n",
       "1008  P010012  1(esze3@c) GAN2 ur-{d}nin-PA-ke4 lugal-USZ-MUS...\n",
       "1009  P010011  6(asz@c) uruda ma-na sa10 GAN2 4(iku@c) GAN2-b...\n",
       "1010  P010009  [6(asz@c)] uruda ma-na sa10 GAN2 4(iku@c) GAN2...\n",
       "1011  P010008  4(iku@c) GAN2 DUR2-HAR sar 1(u@c) uruda <a>-ru...\n",
       "1012  P005984  [n] 4(bur3@c) _GAN2_ E2#? HA? GU4? x in ur-sa6...\n",
       "\n",
       "[1013 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed3a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
