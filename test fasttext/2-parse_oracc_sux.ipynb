{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Represent ORACC Texts in UTF-8 Cuneiform\n",
    "The code in this notebook will parse [ORACC](http://oracc.org) `JSON` files to extract signs from the Sumerian texts of one or more projects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "util_dir = os.path.abspath('../utils')\n",
    "sys.path.append(util_dir)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Create Directories, if Necessary\n",
    "The two directories needed for this script are `jsonzip` and `output`. If they do not exist they are created, else: do nothing.\n",
    "\n",
    "For the code, see [Stack Overflow](http://stackoverflow.com/questions/18973418/os-mkdirpath-returns-oserror-when-directory-does-not-exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['jsonzip', 'output', 'corpus']\n",
    "make_dirs(directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Input Project Names\n",
    "Provide a list of one or more project names, separated by commas. Note that subprojects must be listed separately, they are not included in the main project. For instance:\n",
    "\n",
    "`epsd2/admin/ed3a, epsd2/admin/ed3b, epsd2/admin/ebla, epsd2/admin/oakk, epsd2/admin/lagash2, epsd2/admin/u3adm, epsd2/admin/u3let, epsd2/admin/u3leg, epsd2/admin/oldbab, epsd2/literary, epsd2/emesal, epsd2/earlylit, epsd2/royal, epsd2/praxis, epsd2/praxis/liturgy, dcclt, dcclt/nineveh, dcclt/signlists, obmc, ckst, blms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Project(s):  epsd2/admin/lagash2\n"
     ]
    }
   ],
   "source": [
    "projects = input('Project(s): ').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Split the List of Projects and Download the ZIP files.\n",
    "Split the list of projects and create a list of project names, using the `format_project_list()` and `oracc_download()` functions in the `utils` module. The code of these functions is discussed in more detail in 2.1.0. Download ORACC JSON Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving http://build-oracc.museum.upenn.edu/json/epsd2-admin-lagash2.zip as jsonzip/epsd2-admin-lagash2.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b95d5d9f32049ad8698ee0e0c4866de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epsd2/admin/lagash2', max=3423458.0, style=ProgressStyle(‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['epsd2/admin/lagash2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = format_project_list(projects)\n",
    "oracc_download(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"head21\"></a>2.1 The `parsejson()` function\n",
    "The `parsejson()` function will \"dig into\" the `json` file (transformed into a dictionary) until it finds the relevant data. The `json` file consists of a hierarchy of `cdl` nodes; only the lowest nodes contain lemmatization data. The function goes down this hierarchy by calling itself when another `cdl` node is encountered. For nore information about the data hierarchy in the [ORACC](http://oracc.org) `json` files, see [ORACC Open Data](http://oracc.museum.upenn.edu/doc/opendata/index.html).\n",
    "\n",
    "The argument of the `parsejson()` function is a `JSON` object, a dictionary that initially contains the entire contents of the original JSON file. The code takes the key `cdl` which itself contains an array (a list) of `JSON` objects. Iterating through these objects, if an object contains another `cdl` node, the function calls itself with this object as first argument. This way the function digs deeper and deeper into the `JSON` tree, until it does not encounter a `cdl` key anymore. Here we are at the level of individual words. The code checks for a key `f`, if it exists the signs are in the node `gdl` within the `f` node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsejson_signs(text):\n",
    "    for JSONobject in text[\"cdl\"]:\n",
    "        field = ''\n",
    "        if \"cdl\" in JSONobject: \n",
    "            parsejson_signs(JSONobject)\n",
    "        if \"type\" in JSONobject and JSONobject[\"type\"] == \"field-start\":\n",
    "            field = JSONobject[\"subtype\"]\n",
    "        if \"f\" in JSONobject and not field in ['sg', 'pr']: # skip the fields \"sign\" and \"pronunciation\"\n",
    "                                # in lexical texts\n",
    "            if JSONobject[\"f\"][\"lang\"][:3] == \"sux\": #only Sumerian and Emesal\n",
    "                word = JSONobject[\"f\"]\n",
    "                f = word[\"form\"]\n",
    "                if \"sexified\" in word[\"gdl\"][0]:\n",
    "                    f = word[\"gdl\"][0][\"sexified\"]\n",
    "                if \"cf\" in word:\n",
    "                    if 'pos' in word:  #for some reason some words appear without pos. Provisionally treated as Noun\n",
    "                        lemm = word[\"cf\"] + '[' + word[\"gw\"] + \"]\" + word[\"pos\"]\n",
    "                    else:\n",
    "                        lemm = word[\"cf\"] + '[' + word[\"gw\"] + \"]N\"\n",
    "                    lemm = lemm.replace(' ', '-') # remove commas and spaces from lemm\n",
    "                    lemm = lemm.replace(',', '')\n",
    "                else:\n",
    "                    lemm = word[\"form\"] # if word is unlemmatized\n",
    "                all_.append(f)\n",
    "                lemm_.append(lemm)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Call the `parsejson()` function for every `JSON` file\n",
    "The code in this cell will iterate through the list of projects entered above (1.1). For each project the `JSON` zip file is located in the directory `jsonzip`, named PROJECT.zip. \n",
    "\n",
    "Each of these files is extracted from the `zip` file and read with the command `json.loads()`, which reads the json data and transforms it into a Python dictionary (a sequence of keys and values).\n",
    "\n",
    "This dictionary, which is called `text` is now sent to the `parsejson()` function. The function adds signs to the `sign_l` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e564645d114d0d8eecbcff310ae6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epsd2/admin/lagash2', max=551.0, style=ProgressStyle(desc‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_ = []\n",
    "lemm_ = []\n",
    "ids_ = []\n",
    "for project in p:\n",
    "    file = \"jsonzip/\" + project.replace(\"/\", \"-\") + \".zip\"\n",
    "    try:\n",
    "        z = zipfile.ZipFile(file)       # create a Zipfile object\n",
    "    except:\n",
    "        print(file + \" does not exist or is not a proper ZIP file\")\n",
    "        continue\n",
    "    files = z.namelist()     # list of all the files in the ZIP\n",
    "    files = [name for name in files if \"corpusjson\" in name and name[-5:] == '.json']                                                                                                  #that holds all the P, Q, and X numbers.\n",
    "    for filename in tqdm(files, desc = project):                            #iterate over the file names\n",
    "        id_no = filename[-13:-5]\n",
    "        if id_no in ids_ and not \"X\" in id_no: # Check if P/Q number is already in there\n",
    "            continue        # a text may appear in multiple projects\n",
    "        id_text = project + id_no # id_text is, for instance, blms/P414332\n",
    "        try:\n",
    "            text = z.read(filename).decode('utf-8')         #read and decode the json file of one particular text\n",
    "            data_json = json.loads(text)                # make it into a json object (essentially a dictionary)\n",
    "            all_.append('Start'+id_text)\n",
    "            lemm_.append('Start'+id_text)   # to keep all_ and lemm_ same length\n",
    "            parsejson_signs(data_json)\n",
    "            ids_.append(id_no)\n",
    "            #print(filename)\n",
    "        except:\n",
    "            print(id_text + ' is not available or not complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data Structuring\n",
    "### 3.1 Transform the Data into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e737a42e4c4866acaf319030f56f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19057.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_l = []\n",
    "separators = ['{', '}', '-']\n",
    "separators2 = ['.', '+', '|']\n",
    "operators = ['&', '%', '@', '√ó']\n",
    "for e in tqdm(all_):\n",
    "    word = []\n",
    "    if '1(≈°ar‚ÇÇ{gal})' in e: # this cheating but it seems to work (appears in SKL 38)\n",
    "            e = e.replace('1(≈°ar‚ÇÇ{gal})', '1(≈°ar‚ÇÇ)-gal')\n",
    "    for s in separators: # first split word into signs   \n",
    "        e = e.replace(s, ' ').strip()\n",
    "    s_l = e.split()\n",
    "    for sign in s_l:\n",
    "        if sign[0].isdigit(): # 1(ge≈°‚ÇÇ), 2(DI≈†), etc.\n",
    "            sign = sign.lower()\n",
    "        elif sign[-1] == ')': # qualified sign - get only the qualifier\n",
    "            stack = []  # |GI≈†√ó(GI≈†%GI≈†)|(LAK277) becomes LAK277\n",
    "            ind = {}    # LAK277(|GI≈†√ó(GI≈†%GI≈†)|) becomes |GI≈†√ó(GI≈†%GI≈†)|\n",
    "            for i, c in reversed(list(enumerate(sign))):\n",
    "                if c == ')':\n",
    "                    stack.append(i)\n",
    "                if c == '(':\n",
    "                    ind[stack.pop()] = i   # find the opening parens that belongs to the closing parens at position -1    \n",
    "            start = ind[len(sign)-1]   # this line fails on 1(≈°ar‚ÇÇ{gal}) in SKL.\n",
    "            t = sign[start+1:-1]\n",
    "            if t.isupper(): #leave 1(di≈°) etc. alone\n",
    "                sign = t\n",
    "            \n",
    "        if '|' in sign:  # separate |DU.DU| and |DU+DU| into its components but not |DU&DU|\n",
    "                        # and also not |DU.DU&DU|\n",
    "            flag = False\n",
    "            for o in operators:\n",
    "                if o in sign:\n",
    "                    flag = True\n",
    "            if not flag:\n",
    "                for s in separators2:\n",
    "                    sign = sign.replace(s, ' ').strip() \n",
    "                sign_l = sign.split()\n",
    "                word.extend(sign_l)\n",
    "                continue\n",
    "        elif \"+\" in sign:  # + as marker of gloss\n",
    "            sign = sign.replace('+', ' ').strip()\n",
    "            sign_l = sign.split()\n",
    "            word.extend(sign_l)\n",
    "            continue\n",
    "        word.append(sign)\n",
    "    words_l.append(word)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/ogsl.p\", \"rb\") as f:\n",
    "    o = pd.read_pickle(f, compression = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = list(o[\"value\"])\n",
    "utf = list(o[\"utf8\"])\n",
    "names = list(o[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(names, utf))\n",
    "d2 = dict(zip(val,names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d68e85e30f43acb4b8f04936915936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19057.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "names_l = []\n",
    "utf8_l = []\n",
    "for w in tqdm(words_l):\n",
    "    seq = [d2[s.lower()] if s.lower() in d2 else s for s in w]\n",
    "    names_l.append(seq)\n",
    "    utf8 = [d[n] if n in d else n for n in seq]\n",
    "    utf8_l.append(''.join(utf8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transliteration</th>\n",
       "      <th>words</th>\n",
       "      <th>names</th>\n",
       "      <th>utf-8</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Startepsd2/admin/lagash2/P213108</td>\n",
       "      <td>[Startepsd2/admin/lagash2/P213108]</td>\n",
       "      <td>[Startepsd2/admin/lagash2/P213108]</td>\n",
       "      <td>Startepsd2/admin/lagash2/P213108</td>\n",
       "      <td>Startepsd2/admin/lagash2/P213108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2(a≈°@c)</td>\n",
       "      <td>[2(a≈°@c)]</td>\n",
       "      <td>[2(A≈†)]</td>\n",
       "      <td>íêÄ</td>\n",
       "      <td>2(a≈°@c)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tug‚ÇÇ</td>\n",
       "      <td>[tug‚ÇÇ]</td>\n",
       "      <td>[TUG‚ÇÇ]</td>\n",
       "      <td>íåÜ</td>\n",
       "      <td>tug[textile]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar-dul‚ÇÖ</td>\n",
       "      <td>[bar, dul‚ÇÖ]</td>\n",
       "      <td>[BAR, TUG‚ÇÇ]</td>\n",
       "      <td>íÅáíåÜ</td>\n",
       "      <td>bardul[garment]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guz-za</td>\n",
       "      <td>[guz, za]</td>\n",
       "      <td>[LUM, ZA]</td>\n",
       "      <td>íàùíçù</td>\n",
       "      <td>guz[tufted]V/i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19052</th>\n",
       "      <td>gar-ra</td>\n",
       "      <td>[gar, ra]</td>\n",
       "      <td>[GAR, RA]</td>\n",
       "      <td>íÉªíäè</td>\n",
       "      <td>≈ãar[place]V/t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19053</th>\n",
       "      <td>mu</td>\n",
       "      <td>[mu]</td>\n",
       "      <td>[MU]</td>\n",
       "      <td>íà¨</td>\n",
       "      <td>mu[name]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19054</th>\n",
       "      <td>e‚ÇÇ</td>\n",
       "      <td>[e‚ÇÇ]</td>\n",
       "      <td>[E‚ÇÇ]</td>\n",
       "      <td>íÇç</td>\n",
       "      <td>e[house]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19055</th>\n",
       "      <td>ba-gara‚ÇÇ</td>\n",
       "      <td>[ba, gara‚ÇÇ]</td>\n",
       "      <td>[BA, GA@g]</td>\n",
       "      <td>íÅÄíÇ∂</td>\n",
       "      <td>Ba.gara‚ÇÇ[00]TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19056</th>\n",
       "      <td>ba-du‚ÇÉ-a</td>\n",
       "      <td>[ba, du‚ÇÉ, a]</td>\n",
       "      <td>[BA, KAK, A]</td>\n",
       "      <td>íÅÄíÜïíÄÄ</td>\n",
       "      <td>du[build]V/t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19057 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        transliteration                               words  \\\n",
       "0      Startepsd2/admin/lagash2/P213108  [Startepsd2/admin/lagash2/P213108]   \n",
       "1                               2(a≈°@c)                           [2(a≈°@c)]   \n",
       "2                                  tug‚ÇÇ                              [tug‚ÇÇ]   \n",
       "3                              bar-dul‚ÇÖ                         [bar, dul‚ÇÖ]   \n",
       "4                                guz-za                           [guz, za]   \n",
       "...                                 ...                                 ...   \n",
       "19052                            gar-ra                           [gar, ra]   \n",
       "19053                                mu                                [mu]   \n",
       "19054                                e‚ÇÇ                                [e‚ÇÇ]   \n",
       "19055                          ba-gara‚ÇÇ                         [ba, gara‚ÇÇ]   \n",
       "19056                          ba-du‚ÇÉ-a                        [ba, du‚ÇÉ, a]   \n",
       "\n",
       "                                    names                             utf-8  \\\n",
       "0      [Startepsd2/admin/lagash2/P213108]  Startepsd2/admin/lagash2/P213108   \n",
       "1                                 [2(A≈†)]                                 íêÄ   \n",
       "2                                  [TUG‚ÇÇ]                                 íåÜ   \n",
       "3                             [BAR, TUG‚ÇÇ]                                íÅáíåÜ   \n",
       "4                               [LUM, ZA]                                íàùíçù   \n",
       "...                                   ...                               ...   \n",
       "19052                           [GAR, RA]                                íÉªíäè   \n",
       "19053                                [MU]                                 íà¨   \n",
       "19054                                [E‚ÇÇ]                                 íÇç   \n",
       "19055                          [BA, GA@g]                                íÅÄíÇ∂   \n",
       "19056                        [BA, KAK, A]                               íÅÄíÜïíÄÄ   \n",
       "\n",
       "                                   lemm  \n",
       "0      Startepsd2/admin/lagash2/P213108  \n",
       "1                               2(a≈°@c)  \n",
       "2                         tug[textile]N  \n",
       "3                      bardul[garment]N  \n",
       "4                        guz[tufted]V/i  \n",
       "...                                 ...  \n",
       "19052                     ≈ãar[place]V/t  \n",
       "19053                         mu[name]N  \n",
       "19054                         e[house]N  \n",
       "19055                    Ba.gara‚ÇÇ[00]TN  \n",
       "19056                      du[build]V/t  \n",
       "\n",
       "[19057 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"transliteration\":all_, \"words\":words_l, \"names\":names_l, \"utf-8\":utf8_l, \"lemm\" : lemm_})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus/sux_df.p\", \"wb\") as w:\n",
    "    pickle.dump(df, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as Text\n",
    "Save three different representations of the Sumerian text. Each representation is saved in a separate text file:\n",
    "- in transliteration        ===> sux_tl.txt\n",
    "- in lemmatized format   ===> sux_lemm.txt\n",
    "- in cuneiform (utf-8)    ===> sux_utf8.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_d = {\"sux_utf8\": \"utf-8\", \"sux_lemm\": \"lemm\", \"sux_tl\" : \"transliteration\"}\n",
    "for rep in rep_d:\n",
    "    text = ' '.join(df[rep_d[rep]]).strip()\n",
    "    text = text.replace(' Start', '\\n').strip()\n",
    "    text = text.replace('Start', '')\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    file = \"corpus/\" + rep + \".txt\"\n",
    "    with open(file, 'w', encoding=\"utf-8\") as w:\n",
    "        w.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
